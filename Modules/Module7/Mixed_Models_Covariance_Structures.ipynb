{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6948ebde-9430-4e29-9df5-8090a46295ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Conducting Genetic Evaluations using Mixed Models \n",
    "\n",
    "In this module we will cover the basics of analyzing plant breeding data using mixed models for the purpose of calculating the genetic merit of lines for use as parents commonly referred to as **Estimated Breeding Values (EBV) or Genomic Estimated Breeding Values (GEBV)**. We will only cover 2 examples, but the course will provide some basic information on the sommer package and how to run the analysis using the ILCI JupyterHub Environment. Mixed models are powerful tools for the analysis of breeding data because they can incorporate knowledge of genetic inheritance and genetic control of complex traits, leading to more accurate estimates of genetic merit.\n",
    "\n",
    "**Specifically this module will provide:**\n",
    "\n",
    "- A brief review of inheritance, basic principles of quantitative genetics, and response to selection.\n",
    "- An introduction the the mixed model package sommer and instructions on how to fit and interpret results from the sommer package.\n",
    "- Two examples of fitting mixed models using pedigree and genomic relationship matrices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb93aeed-ecf2-4fa8-8284-2da386bd1c21",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inheritance\n",
    "\n",
    "![](images/Meiosis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffb5add-68fc-4a1d-86fb-b71392f3c4e6",
   "metadata": {},
   "source": [
    " 1.  **Law of segregation**: A trait is influenced by a pair of alleles but each individual passes on to       its progeny a gamete that contains only a single, random, allele.\n",
    "\n",
    "2.  **Law of independent assortment**: Alleles of different factors combine independently in the gamete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be41d0-f27b-43c6-b15e-aae3d111696f",
   "metadata": {},
   "source": [
    "# Inheritance of alleles is random and conditional on the genotype of parents\n",
    "- As a result inheritance follows well defined discrete statistical probability distributions\n",
    "- This combined with the properties of the central limit theorem enable us to treat most complex genetic (influenced by multiple genetic and environmental factors) effects as being normally distributed.\n",
    "- The fact that complex genetic effects tend to follow normal distributions means statistical approaches play a critical role in plant breeding efforts.\n",
    "- **Quantitative Genetics** is a field of science that specializes in developing and applying statistical modeling to better understand and more effectively modify complex genetic traits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9c5ecb-a73a-445f-b414-29a636496085",
   "metadata": {},
   "source": [
    "# Central Limit Theorem\n",
    "CLT states the sum of a large number of independent identically distributed random variables with a finite variance will be approximately normal.\n",
    "\n",
    "In this section, we demonstrate the Central Limit Theorem using a graphical approach. We generate a sample data set following an exponential distribution using the rexp function. The goal is to visualize the distribution of these data points.\n",
    "\n",
    "We utilize the ggplot2 library for creating histograms. The geom_histogram function is used to create a histogram of the data, allowing us to observe the population distribution. Various aesthetic elements are added for clarity, including labeling the x-axis, setting a title, and customizing the theme for better visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6d5bf-8478-4193-8f81-6e61af8b8322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Central Limit Demo\n",
    "library(ggplot2)\n",
    "set.seed(100)\n",
    "dat = rexp(10000)\n",
    "#dat=runif(10000)\n",
    "ggplot(data.frame(x=dat), aes(x=x)) +\n",
    "  geom_histogram(aes(y = after_stat(density)), binwidth=.1 ) + xlab(\"x value\") +\n",
    "  ggtitle(\"Population Distribution\") +\n",
    "  theme_bw(base_size=18) +\n",
    "  theme(panel.background=element_blank(),\n",
    "        panel.grid=element_blank())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71889067-da86-4a4c-936a-409f26a23564",
   "metadata": {},
   "source": [
    "In this section, we demonstrate the concept of sampling distribution of the sample mean. We begin by setting a seed for reproducibility. Our goal is to understand how the means of samples, taken from our original dataset, distribute themselves.\n",
    "\n",
    "We conduct a simulation where we repeatedly draw samples of size 30 from our dataset dat, compute their means, and store these means in an array. This process is repeated 1000 times to generate a robust sample of means.\n",
    "\n",
    "After accumulating these sample means, we plot their distribution using ggplot2. The resulting histogram will help us observe the distribution of the sample means, which is a critical concept in understanding the Central Limit Theorem. The histogram is styled for better readability and aesthetics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d38ca7-d658-4559-b180-27302192a3da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(100)\n",
    "samples <- c()\n",
    "for(i in 1:1000){\n",
    "  samples <- c(samples, mean(sample(dat, 30)))\n",
    "}\n",
    "ggplot(data.frame(x=samples), aes(x=x)) +\n",
    "  geom_histogram(aes(y = after_stat(density)), binwidth=.05 ) + xlab(\"x value\") +\n",
    "  ggtitle(\"1000 Means of 30 from Population\") +\n",
    "  theme_bw(base_size=18) +\n",
    "  theme(panel.background=element_blank(),\n",
    "        panel.grid=element_blank())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac7d818-0dab-467f-8ebc-686f2d102039",
   "metadata": {},
   "source": [
    "# How many genes need to control a trait before the genetic effects follow a normal distribution?\n",
    "\n",
    "This section focuses on simulating the genetic effects of quantitative trait loci (QTL) that control a particular trait of interest. We define the number of QTLs and simulate their effects on a population of 1000 lines.\n",
    "\n",
    "**Initialization**: We start by specifying the number of QTLs (`nQTL`) influencing the trait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f209c5-e461-4acc-bab0-ec7294c1c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of quantitative trait loci controlling the trait of interest\n",
    "nQTL=7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31279e6e-093e-41fe-958b-896739384f67",
   "metadata": {},
   "source": [
    "**Storage Vector**: A vector (`gEffects`) is initialized to store the cumulative effect of QTLs for each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93670da3-b1a3-49ce-b61b-e84e5350ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocating a vector to store the sum of QTL effects for 1000 lines\n",
    "gEffects=rep(0,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5186ea-4994-4af2-867a-df06297aa5e2",
   "metadata": {},
   "source": [
    "**QTL Effect Simulation**: The effects of each QTL are simulated using a uniform distribution. This represents the random nature of genetic variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d42472-152f-492b-bc1d-96f29f0a9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulating QTL effects using a uniform distribution (0,1)\n",
    "QTLeffect=runif(nQTL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06bf42b-9b2e-43b3-a7d4-882738332d39",
   "metadata": {},
   "source": [
    "**Sampling Genotypes**: We simulate bi-allelic polymorphisms for each line, assuming a high minor allele frequency. The genotype at each locus is determined by sampling, and the effect of each allele is added to or subtracted from the total genetic effect for each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db23d6-5e49-4be1-accd-c113b3dcc028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling bi-allelic polymorphisms for 10000 lines\n",
    "# Assuming a high minor allele frequency of .4\n",
    "# setting up a loop to sample genotypes \n",
    "for(i in c(1:1000)){\n",
    "    for(j in c(1:nQTL)){\n",
    "        # sample first allele at the jth locus\n",
    "        if(runif(1)>.4){\n",
    "            #adding allele effect for the ith line\n",
    "            gEffects[i]=gEffects[i]+QTLeffect[j]\n",
    "        } else {\n",
    "            gEffects[i]=gEffects[i]-QTLeffect[j]\n",
    "        }\n",
    "            \n",
    "        # sample second allele a jth locus\n",
    "        if(runif(1)>.4){\n",
    "            #adding allele effect for the ith line\n",
    "            gEffects[i]=gEffects[i]+QTLeffect[j]\n",
    "        } else {\n",
    "            gEffects[i]=gEffects[i]-QTLeffect[j]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489a0d3a-8758-438b-b6b0-d48465492d50",
   "metadata": {},
   "source": [
    "**Visualization**: Finally, we plot the distribution of genetic effects across the 1000 lines using `ggplot2`. This histogram provides insights into the variability of genetic contributions across different lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf8e1f-023f-4290-aed0-68501bb98959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ggplot(data.frame(x=gEffects), aes(x=x)) +\n",
    "  geom_histogram(aes(y = after_stat(density)), binwidth=.2 ) + xlab(\"genetic value\") +\n",
    "  ggtitle(\"Distribution of genetics effects\") +\n",
    "  theme_bw(base_size=18) +\n",
    "  theme(panel.background=element_blank(),\n",
    "        panel.grid=element_blank())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ea8d0-9c47-44cd-994e-10d6f768c0ef",
   "metadata": {},
   "source": [
    "# Activity:\n",
    "Use the above code and modify the number of QTL controlling the trait of interest 'nQTL'. Approximately how many QTL need to be controlling the trait before the distribution on genetic values looks normal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a05ab3-a824-45d5-bf30-2fa8b0567224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of quantitative trait loci controlling the trait of interest\n",
    "nQTL=5\n",
    "# allocating a vector to store the sum of QTL effects for 1000 lines\n",
    "gEffects=rep(0,1000)\n",
    "# simulating QTL effects using a uniform distribution (0,1)\n",
    "QTLeffect=runif(nQTL)\n",
    "# Sampling bi-allelic polymorphisms for 10000 lines\n",
    "# Assuming a high minor allele frequency of .4\n",
    "# setting up a loop to sample genotypes \n",
    "for(i in c(1:1000)){\n",
    "    for(j in c(1:nQTL)){\n",
    "        # sample first allele at the jth locus\n",
    "        if(runif(1)>.4){\n",
    "            #adding allele effect for the ith line\n",
    "            gEffects[i]=gEffects[i]+QTLeffect[j]\n",
    "        } else {\n",
    "            gEffects[i]=gEffects[i]-QTLeffect[j]\n",
    "        }\n",
    "            \n",
    "        # sample second allele a jth locus\n",
    "        if(runif(1)>.4){\n",
    "            #adding allele effect for the ith line\n",
    "            gEffects[i]=gEffects[i]+QTLeffect[j]\n",
    "        } else {\n",
    "            gEffects[i]=gEffects[i]-QTLeffect[j]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "ggplot(data.frame(x=gEffects), aes(x=x)) +\n",
    "  geom_histogram(aes(y = after_stat(density)), binwidth=.2 ) + xlab(\"genetic value\") +\n",
    "  ggtitle(\"Distribution of genetics effects\") +\n",
    "  theme_bw(base_size=18) +\n",
    "  theme(panel.background=element_blank(),\n",
    "        panel.grid=element_blank())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01063219-e7ca-4d13-ad92-5f61216986e8",
   "metadata": {},
   "source": [
    "**Answer -**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e459d92c-18aa-476c-b7e7-f7f4df120d53",
   "metadata": {},
   "source": [
    "# Moments of a statistical distribution.\n",
    "\n",
    "The central moments of a statistical distribution represented by a **probability density function (PDF)** describe important attributes of the ditribution. In particular the first two central moments are important for mixed models and calculating expected response to selection (covered later).\n",
    "\n",
    "The mean **$\\mu$** is the first moment of the distribution and it provides information on the center of the distribution.\n",
    "\n",
    "The variance **$\\sigma^2$** is the second central moment and provides information on the spread of data points around the mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e369000-fda3-49da-bc39-8655009f0267",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Linear Models\n",
    "\n",
    "When we use the term \"Linear Model\" we are refering to a model in which the models effects are estimated as a linear function of the dependent variable - the **phenotype** in the case of plant breeding applications.\n",
    "\n",
    "The dependent variable is often denoted as $y$\n",
    "\n",
    "When deriving estimators for linear models there are certain properties that are desirable:\n",
    "\n",
    "- **Best** - This means the estimator has the minimum error variance of all possible linear estimators.\n",
    "- **Linear** - As previously mention, this mean the estimator is a linear function of of $y$. The mean is a simple example of a linear estimator as:\n",
    "        $\\bar{y}=\\frac{\\sum_{i=1}^{n} y_i}{n}$ \n",
    "- **Unbiased** - An estimator is unbiased when the expectation of the estimator is equal to the expectation of the true value. In other words, as the amount of information used to calculate the estimator increase, the error in the estimate decrease towards 0.\n",
    "\n",
    "When using linear model software in R, the obtained estimates of model effects are the **Best Linear Unbiased Estimates** or **BLUE**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c56298-f0a6-45d9-8132-65c26fa1384f",
   "metadata": {},
   "source": [
    "# Partitioning of Phenotypes\n",
    "\n",
    "In Quantitative Genetics the basic linear model partitions observed phenotypes into genetic and environmental effects:\n",
    "\n",
    "$P = G + E$\n",
    "\n",
    "Assuming independence of genetic and environmental effects we can similarly partition phenotype vairance into:\n",
    "\n",
    "$\\sigma_{p}^2=\\sigma_{g}^2+\\sigma_{e}^2$\n",
    "\n",
    "Similarly it is necessary to partition genetic variance into additive ($\\sigma_{a}^2$), epistatic ($\\sigma_{aa}^2$)  and dominance ($\\sigma_{d}^2$)components.\n",
    "\n",
    "$\\sigma_{g}^2=\\sigma_{a}^2+\\sigma_{aa}^2+\\sigma_{d}^2$\n",
    "\n",
    "When making breeding crosses we tend to focus on additive genetic variance because additive genetic effects are what is passed on from parents to progeny."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3af2e9f-f46e-48b7-abe5-2feeef5825f5",
   "metadata": {},
   "source": [
    "# Heritability \n",
    "\n",
    "From this basic linear model and partitioning of phenotypic variance, we can derive the formula for heritability and the equation for response to selection.\n",
    "\n",
    "Broad sense heritability is **$H^2=\\frac{\\sigma_{g}^2}{\\sigma_{p}^2}$**\n",
    "\n",
    "Narrow sense is **$h^2=\\frac{\\sigma_{a}^2}{\\sigma_{p}^2}$** \n",
    "\n",
    "Since narrow sense heritability represents the portion of phenotypic variance explained by additive genetic variance we can calculate the expected response to selection as a function of  **$h^2$** and the **selection differential** - the difference in the phenotypic mean of selected individuals and the population from with the individuals were selected. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da994dad-98b1-4f65-bb52-ed191c62beef",
   "metadata": {},
   "source": [
    "# Response to selection\n",
    " \n",
    "\n",
    " $R=h^2*S$\n",
    " \n",
    "Here $R$ is the response to selection; $h^2$ the narow sense heritabilited; and $S$ is the selection differential as described above.\n",
    " \n",
    "When the phenotype of interest in normally distributed, which is often the case given the properties of Central Limit Theorem, $S$ can be expressed in terms of the standard deviations $S = i*\\sigma_{P}$\n",
    "\n",
    "![](images/selection_differential.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73224a7-02d5-4b27-9734-cd676ef06ef4",
   "metadata": {},
   "source": [
    "# Breeder's Equation \n",
    "\n",
    "When the data is normally distributed we can represent the response to selection as:\n",
    "\n",
    "$R=i*h^2*\\sigma_{P}$\n",
    "\n",
    "With some algebra we can also represent response to selection as:\n",
    "\n",
    "$R=i*h*\\sigma_{a}$\n",
    "\n",
    "The above equation gives us the response to selection when selecting on the phenotype or phenotypic means.\n",
    "\n",
    "When using more advanced models that generate more accruate estimates of genetic merit, it is preferred to replace **$h$** with **$r$** , where **$r$** is the accuracy of the estimate of genetic merit.\n",
    "\n",
    "$R=i*r*\\sigma_{a}$\n",
    "\n",
    "Often it is response to selection per year that is of most interest to breeders. To get this value we must divide respoinse to selection by the genration interval **$L$**. \n",
    "\n",
    "Generation interval is the number of years it takes to slection the progrney og a breeding cross to be the parents of the next generation.\n",
    "\n",
    " $R_{year}=\\frac{i*r*\\sigma_{a}}{L}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a51447-2b6a-443c-b70f-21246b490cbc",
   "metadata": {},
   "source": [
    "# Mixed Models\n",
    "\n",
    "Mixed models contain fixed effects and random effects. The estimate of a random effect is referred to as a **Best Linear Unbiased Predictors (BLUP)**. Here Best and Linear have the same meaning as previously described for BLUEs. The term unbiased is slightly different for random effects, but will not be covered in detail here.\n",
    "\n",
    "When treating something as a random effect, we make specific assumptions about the statistical distribution that gives rise to the observed random effects. When our assumptions about the statistical distribution are correct, and we have enough data to accurately estimate the parameters of the distribution (specifically the variance and covariance), then the additional information tends to result in more accruate estimates of effects.\n",
    "\n",
    "To illustate this let's take a simple example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db3fbd9-235b-40ed-a861-bace6372fb59",
   "metadata": {},
   "source": [
    "# Fitting Mixed Models\n",
    "\n",
    "Let's start with an example that uses our knowledge of inheritance to improve the accuracy of selection.\n",
    "When using means as estimates of genetic merit accuracy ( **$r$** ) is calculated as:\n",
    "\n",
    "$r=\\sqrt{\\frac{\\sigma_{a}^2}{\\sigma_{a}^2+\\frac{\\sigma_{e}^2}{n_{rep}}}}$\n",
    "\n",
    "This is the case when mean performance is used as the selection criterion.\n",
    "Given our understanding of inheritance we can fit more accurate models by ustilizing information on genetic relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee0435c-50a0-4e53-8f03-777e87aad909",
   "metadata": {},
   "source": [
    "# Genetic Relationships: Identity by Descent\n",
    "\n",
    "Covariance is a measure of the relationship between two vairables. When positive the two variables will tend to move in the same direction and when negative the two variables will tend to move in opposite directions.\n",
    "\n",
    "The genetic covariance between individuals for a given phenotype is determined by common alleles for the QTL that explain variance for the phenotype\n",
    "\n",
    "In the absence of detailed information on the QTL, the covariance can be approximated by calculating the probability two individuals carry alleles that are identical by descent (IBD).\n",
    "\n",
    "- IBD represents the probability that the same allele is inherited by two individuals from some common ancestor.\n",
    "- These calculations can be done using pedigrees or genotypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b9f899-6faf-4875-a99a-972527a9a1ce",
   "metadata": {},
   "source": [
    "# A Simple Illustration\n",
    "In this exmple we are testing lines from 2 unrelated full sib families. The code below will analyze a polygenic trait and compare prediction accuracy using a model that ignores genetic relationships and a mixed model that accounts for the relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8baadd9-7d4b-452f-abd2-d01060943bc9",
   "metadata": {},
   "source": [
    "# Reading the data\n",
    "\n",
    "First let's read in the dataset and look at its contents.\n",
    "\n",
    "The data is stored as a csv file so we will use the `read.csv` command in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3709a54-164a-4db1-b6ec-e3fe6269ab8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading the data and storing it as phenodat\n",
    "\n",
    "phenodat=read.csv(\"datasets/Family_data.csv\",header=TRUE)\n",
    "\n",
    "# Header = TRUE because the file has a header row in it.\n",
    "\n",
    "summary(phenodat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1193eba6-0a6c-45f2-94ba-a8790521848d",
   "metadata": {},
   "source": [
    "Using the summary command we can that we have 3 blocks in the dataset and 30 varieties. There is a simulated phenotype and the true simulated genetic merit of the varieties. We will fit 2 models to this dataset:\n",
    "\n",
    "- Model 1 will treat variety as a fixed effect.\n",
    "- Model 2 will treat variety as a random effect and will account for pedigree relationships.\n",
    "\n",
    "First we must read in the pedigree relationship matrix in file \"Amat.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ca9a9-2d26-4f24-9c18-b5594d868606",
   "metadata": {},
   "source": [
    "# Reading the Pedigree Relationship Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f5dea-38bf-443a-83a8-ef1f43d70efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading the data and storing it as phenodat\n",
    "\n",
    "Amat=read.csv(\"datasets/Amat.csv\",header=FALSE)\n",
    "\n",
    "# Header = FALSE because the file has no header row in it.\n",
    "\n",
    "#converting to a matrix\n",
    "Amat=as.matrix(Amat)\n",
    "\n",
    "#creating a heatmap of the pedigree relationship matrix file\n",
    "\n",
    "image(Amat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e5f51-b0e1-4a5b-8a92-ec27aa929265",
   "metadata": {},
   "source": [
    "Here we can see that we have two blocks of highly related (orange color) lines that are from the two full-sib families. The two families are unrelated to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136359f3-35b8-4de7-8edd-ccc1c4677ead",
   "metadata": {},
   "source": [
    "# The Sommer Mixed Model Package\n",
    "\n",
    "To fit the models we will be using the R package \"sommer\". There are many mixed model packages available and each have thier own specific syntax for specifying models. We strongly recmomend reading the manual for sommer before using the package (https://cran.r-project.org/web/packages/sommer/sommer.pdf).\n",
    "\n",
    "The manaul will give you examples of how to specify models and retrieve estimates from the output. For mixed models it is also important to know how to specify (co)variance structures. In this module we will give some examples but sommer is capable of supporting many (co)vairance sturctures that we will not cover here. It is encouraged that after students feel comfortable fitting basic models, they explore fitting more complex models from the sommer quick start guides:\n",
    "\n",
    "- https://cran.r-project.org/web/packages/sommer/vignettes/v1.sommer.quick.start.pdf\n",
    "- https://cran.r-project.org/web/packages/sommer/vignettes/v3.sommer.qg.pdf\n",
    "- https://cran.r-project.org/web/packages/sommer/vignettes/v4.sommer.gxe.pdf\n",
    "- https://cran.r-project.org/web/packages/sommer/vignettes/v6.sommer.spatial.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f5455-b6ad-4832-b935-1982c65e8613",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating a data frame\n",
    "\n",
    "The sommer package requires datasets to be in an object called a dataframe. In our case we are reading in the data as a dataframe but we will creat a new data to illustrate how is is done with data htat is in a matrix format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8bd5f-1f65-4bba-b567-0f47153b23c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating a data frame from the input data\n",
    "\n",
    "phenodatdf<-data.frame(block=as.factor(phenodat[,1]),variety=as.factor(phenodat[,2]), phenotype=as.double(phenodat[,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30291ad6-73fb-4065-9373-0cd7ee7f8538",
   "metadata": {},
   "source": [
    "When creating the data frame we name each column in the data set and these are the names we will use when specifying the model\n",
    "\n",
    "For effects in which we want to estimate values for each level (i.e. block) we use the `as.factor()` command so sommer will know hoe to treat the effect in the model. In the case of block the numbers for each block (1,2,3) are arbitrary and have no relation to the effect of block. The same is true for variety.\n",
    "\n",
    "For effects in which the numeric value has meaning and we want to fit a regression coefficient, we use the `as.double()` command. We also use the `as.double()` command for the phenotypes we want to model as continuous triats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e0f205-27ff-4865-aa4d-90496bad2bed",
   "metadata": {},
   "source": [
    "# Pedigree Relationships\n",
    "\n",
    "Now that we have the data frame ready for analysis we need to prepare the pedigree relationship matrix for model 2. To do this we need to mapr the varieties in the dataset to the positions in the relationship matrix, and set an attribute to let the sommer package know if it needs to invert the matrix. To make this easy the variety ids in the datafile correspond directly to the position in the relationship matrix.\n",
    "\n",
    "To do this we use the commands: `rownames()`, `colnames()`, and `attr()`. In this casse we are going to set the attribute \"INVERSE\" to FALSE, so sommer knows that the relationship matrix has not been inverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a000a342-0555-44a4-904e-2426e9d657ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rownames(Amat)=levels(phenodatdf$variety)\n",
    "colnames(Amat)=levels(phenodatdf$variety)\n",
    "\n",
    "attr(Amat, \"INVERSE\")=FALSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80932f4e-2abc-4232-a023-cc4a39a73080",
   "metadata": {},
   "source": [
    "# Running the Models\n",
    "\n",
    "Now that the data is prepared for analysis we can run the models and look at the output.\n",
    "\n",
    "We will start by loading the sommer package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2f807-2b93-4a03-b9cc-d72de30f847b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(sommer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54510136-7d8d-4054-bff2-64644c08c905",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model 1 - Variety as fixed\n",
    "\n",
    "First we will run a simple model treating variety and block as fixed. The results of the analysis will be stored as \"model1_ped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8164404a-4afe-42f4-94f9-5de161ea1f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1_ped<-mmer(phenotype ~ block + variety,\n",
    "                 rcov= ~ units,\n",
    "                 data=phenodatdf, verbose= TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c3f612-6a84-4681-ad5c-d40bf0c9c05f",
   "metadata": {},
   "source": [
    "Before we look at the results, let's break down the model statement\n",
    "\n",
    "- `mmer()` is the mixed model solver used by sommer. There is also a `mmec()` function for solving mixed models that we will not cover here. For certain types of analysis 'mmec' will run faster.\n",
    "- The first line of the model statement specifies the phenotype and then the fixed effects \"block and variety.\n",
    "- The second line gives the covariance structure for the residuals `rcov= ~units` is the default structure in which residuals are treated as being identically and indepenedently distributed. When using the default structure this line can be omitted, but there are many ways in which the residual covariance can be modeled and I prefer to always explicitly state the structure I'm using.\n",
    "- The last line tells sommer which data frame to use and I set the verbose flag to TRUE so the **convergence** information is printed to the screen.\n",
    "\n",
    "**Convergence** - Mixed models must be solved iteratively as you need estimates of the model effects to estimate variance composnents and you need the variance components to estimate the random effects. This means the solver must start by randomly initializing the variance components and interatively update the solutions until cpnvergence has been achieled. Mixed models do not always converge for a variety of reasons, so it is important to first check for model convergence before using and of the model outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824813a7-449a-4249-a1f1-6d7eae6d35fc",
   "metadata": {},
   "source": [
    "# Model Output\n",
    "\n",
    "Now lets look at key componente of the model output. First we will use the function `summary()` to look at what is contained in the object **model1_ped**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d57b9-5cb6-42db-8b99-8569ae4bfc1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary(model1_ped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f853f45-356e-44c9-abae-44afbdcc0a58",
   "metadata": {},
   "source": [
    "**$groups** - Provides grouping information for more complicated covariance structures\n",
    "\n",
    "**$varcomp** - provdes estimates of the variance components, in this case only for the residual variance component as there are no random effects in the model.\n",
    "\n",
    "**$beta** - provides the estimates and standard errors of the fixed effects\n",
    "\n",
    "**method** - Gives the method used to solve the mixed model equations `NR` is a second derivative method that will not be covered in this course.\n",
    "\n",
    "**$logo** - Provides information on model fit and whether the model converged. Here we can see that Converged = TRUE, so we know the model converged successfuly. **Always confirm the model converged before using any results**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3a4c8-afd8-42b5-830b-e9139d87dffc",
   "metadata": {},
   "source": [
    "# Solutions\n",
    "\n",
    "To pull out spcific components of **model1_ped** we use `$`\n",
    "\n",
    "The fixed effect solutions can be pulled out of the model object using the command `model1_ped$Beta` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb91020-e5a6-4244-97f2-67577d09fa0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sol_fixed=model1_ped$Beta\n",
    "sol_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a590e8-3700-4a00-a0c6-3325b06a45d2",
   "metadata": {},
   "source": [
    "In the above solutions '(intercept)' is equal to the value of 'variety1' in 'block1', 'block2' and 'block3' are the deviations of the effects of 'blocks 2 and 3' from 'block1', and the estimates of 'variety2 - 30' are deviations from 'variety1'.\n",
    "\n",
    "To get our estimates for variety we are going to add the average of the block effects to the estimates on the variety effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae74b98-1b32-41ad-9359-216c681dac0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1_ped_est=rep(0,30) # vector to store variety estimates\n",
    "block_average = sol_fixed$Estimate[1]/3 + (sol_fixed$Estimate[1] + sol_fixed$Estimate[2])/3 + (sol_fixed$Estimate[1] + sol_fixed$Estimate[3])/3 # averaging the block effects \n",
    "model1_ped_est[1] = 0 + block_average # deviation of 'variety1' from 'variety1' is 0\n",
    "model1_ped_est[2:30]= sol_fixed$Estimate[4:32] + block_average\n",
    "model1_ped_est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67d891c-595b-451c-b02e-14efdf2a64cb",
   "metadata": {},
   "source": [
    "Now I have my estimates from model 1, let's run a second model that treats variety as a random effect and uses the pedigree relationship matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f9207a-a655-4a50-9d2d-c6d630a9ac2a",
   "metadata": {},
   "source": [
    "# Model 2 - Variety as Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82712295-f8d6-4dae-a300-1322b8ea4e85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2_ped <- sommer::mmer(phenotype~block, \n",
    "              random= ~ vsr(variety, Gu=Amat),\n",
    "              rcov= ~ units,\n",
    "              data=phenodatdf, verbose = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c4f212-9dfb-42a4-bf81-92b9b39b3bd9",
   "metadata": {},
   "source": [
    "As you can see the model statement is similar but we now have a new row for the random effect: `random= ~ vsr(variety, Gu=Amat),`\n",
    "\n",
    "`random= ~` tells the model that we are giving it terms we want to treat as random.\n",
    "\n",
    "`vsr()` is a command that we use to specify variance structures\n",
    "\n",
    "In this case we are using `vsr()` to tell sommer we want to model variety as random with a user defined relationship matrix. `Gu` stands for covariance struture (G) that is user (u) defined.\n",
    "\n",
    "There are many different ways to construct covariance structures using  kronecker product between matrices and I highly encourage those who are interested to learn more about how to define more complex structures, but that is out of scope for this class.\n",
    "\n",
    "for more information on the kronecker product see: https://en.wikipedia.org/wiki/Kronecker_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ed8f8-d105-4717-914e-daaf5c4d3cb4",
   "metadata": {},
   "source": [
    "Now let's sort the data and generate the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98e1df-5f07-4743-8f08-55f9c570786a",
   "metadata": {},
   "source": [
    "For more complicated mixed models it is easier to use the `predict.mmer()` function. To use the predict.mmer function we need to pull the DTable variable out of the model fit object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6627976-067c-4797-8f27-f7b7cb6c66ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtm2=model2_ped$Dtable\n",
    "dtm2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dfe229-095a-4806-89d8-8560fd066413",
   "metadata": {},
   "source": [
    "The Dtable has one row for each variable in the model. We will modify the 'include' and 'average' columns in the table to indicate which variables we want included in the prediction and for the variables included, whether or not we want them averaged.\n",
    "\n",
    "For the variable of interest, variety in this case, we will include but not average. We always will include the intercept (denoted as 1 in the first row). In gereral we will always include and average fixed effects that are not of interest for the predictions, this ensures we get the correct standard errors for our predictions.\n",
    "\n",
    "Now lets modify the `dtm2` to get the predictions we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01be5b66-fddf-4a0b-a062-f07cc38eb078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtm2[1,\"include\"]=TRUE # intercept\n",
    "dtm2[2,\"include\"]=TRUE # block\n",
    "dtm2[2,\"average\"]=TRUE # block\n",
    "dtm2[3,\"include\"]=TRUE # variety\n",
    "dtm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd36f772-4445-4bb6-a35b-0b64d7cd1d4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aM2_ped=predict.mmer(model2_ped, Dtable= dtm2, D=\"variety\")\n",
    "#getting the predicted values\n",
    "summary(aM2_ped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91ecf9d-6310-4ad2-a886-a15cf1ce5bf5",
   "metadata": {},
   "source": [
    "The object aM2 has the matrices used to calculate the predictions and the standard errors of the predictions; however, we are only interested in the predicted values 'pvals'. Let's pull out the predicted values to compare to the fixed effect models and the true simulated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51b34c-138a-41a8-92e8-425bfd57f9c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pM2_ped=aM2_ped$pvals\n",
    "pM2_ped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b4dc4-54cc-445a-b8c6-bccf9e9044d0",
   "metadata": {},
   "source": [
    "# Comparing Models\n",
    "\n",
    "Now that we have results fro mthe models let's compare performance.\n",
    "\n",
    "First let's plot the solutions from model 1 against model 2 to see how similar the results are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead3ef9e-cf42-4e17-978b-46cdec55c5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot(model1_ped_est,pM2_ped$predicted.value, main=\"Plot of variety BLUEs vs Pedigree BLUPs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2bd1c6-25d9-4ed5-872d-e20004072530",
   "metadata": {},
   "source": [
    "In this plot the BLUPs are on the y-axis and the BLUEs are on the x-axis. An interestng pattern can be clearly seen in the plot. The BLUPs group into two distinct lines. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a2bd8-38a6-4026-96d2-5d8052b6d672",
   "metadata": {},
   "source": [
    "# Question: \n",
    "Why would the use of the pedigree relationship matrix result in two distinct clusters of Estimate Breeding Vaues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c2c9b-c3cd-447e-9a9b-0933628d0a8c",
   "metadata": {},
   "source": [
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e27888-c209-496b-ab80-a74bbd353df4",
   "metadata": {},
   "source": [
    "# Accuracy of the Estimates\n",
    "\n",
    "To look at the accuracy of the estimates we will correlation the Estimated Breeding values from from model 1 and model 2 with the true breeding values.\n",
    "\n",
    "First let's pull the true values out of phenodat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2dd0a-e27d-4023-be4b-24e61700f817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "True_EBV=phenodat[1:30,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd70cfd-efe7-48f6-96f5-19be917edfa3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now let's calculate accuracy by correlating the estimate values from each model with the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3d071-ca59-40ef-8dfb-0dce7ee44319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Correlation of model 1 estimates and True Breeding Values\")\n",
    "print(cor(model1_ped_est,True_EBV))\n",
    "\n",
    "print(\"Correlation of model 2 estimates and True Breeding Values\")\n",
    "print(cor(pM2_ped$predicted.value,True_EBV))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a5692e-12c8-4ce4-8558-45d01cd1fa32",
   "metadata": {},
   "source": [
    "As the results show, accounting for the pedigree relationships results in more accurate estimates of the true breeding values. This increase in accuracy would result in an increase in response to selection simply by analyzing the data using a more informative mixed model as opposed to a simple model treating variety as a fixed effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b1614-08ca-406a-88c5-f2e794bbbf79",
   "metadata": {},
   "source": [
    "# Activity:\n",
    "Run model 2 without the pedigree relationship matrix (`random= ~ vsr(variety)`). How does that impact the accuracy and change the plots of the solutions for model 1 and model 2? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acab6970-4558-4b3f-be68-8676c82e0443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model 2 no ped\n",
    "model2_no_ped <- sommer::mmer(phenotype~block, \n",
    "              random= ~ vsr(variety),\n",
    "              rcov= ~ units,\n",
    "              data=phenodatdf, verbose = TRUE)\n",
    "\n",
    "dtm2np=model2_no_ped$Dtable\n",
    "dtm2np\n",
    "\n",
    "dtm2np[1,\"include\"]=TRUE # intercept\n",
    "dtm2np[2,\"include\"]=TRUE # block\n",
    "dtm2np[2,\"average\"]=TRUE # block\n",
    "dtm2np[3,\"include\"]=TRUE # variety\n",
    "dtm2np\n",
    "\n",
    "aM2_no_ped=predict.mmer(model2_no_ped, Dtable= dtm2np, D=\"variety\")\n",
    "#getting the predicted values\n",
    "pM2_no_ped=aM2_no_ped$pvals\n",
    "\n",
    "plot(model1_ped_est,pM2_no_ped$predicted.value, main=\"Plot of variety BLUEs vs No Pedigree BLUPs\")\n",
    "\n",
    "print(\"Correlation of model 2 no ped estimates and True Breeding Values\")\n",
    "print(cor(pM2_no_ped$predicted.value,True_EBV))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635ee58-4e1a-4a4d-8380-f52be709315b",
   "metadata": {},
   "source": [
    "# Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e0a55b-85b0-4a0b-b34a-51a9fd922528",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fitting a GxE Model in sommer\n",
    "Genotype by environment interactions (GxE) are commonly observed in multi-environmental trials. Mixed models are well suited for analyzing genotype by environment interactions. Here w will use sommoer to fit some simple GxE models using a genomic relationship matrix.\n",
    "\n",
    "First we will read in the datasets and create a dataframe.\n",
    "\n",
    "The file \"GxE_dataset.csv\" contains experimental information and the phenotype of interest.\n",
    "\n",
    "The file \"GE_GRM.csv\" contains a genomic relationship matrix. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a47f668-85cd-4f4b-b11d-cf5ac08b8cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read phenotypic datafaile\n",
    "phenodat=read.csv(\"datasets/GxE_dataset.csv\",header=TRUE)\n",
    "# create dataframe to pass to the mixed model software\n",
    "dataf=data.frame(loc=as.factor(phenodat$Locations),variety=as.factor(phenodat$Variety),phenotype=as.double(phenodat$Phenotype))\n",
    "#reading in the genomic relationship matrix\n",
    "snpRelMat=read.csv(\"datasets/GE_GRM.csv\",header=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbbbca4-e34f-4a92-883a-1d2c2c2f412b",
   "metadata": {
    "tags": []
   },
   "source": [
    "For genomic relationship matrices it is common to add a small value to the diagonal to ensure that the matrix can be inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5554edb-0e3b-4915-8a2f-6c841f03b560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#adding small value to the diagonal\n",
    "Gsnp=as.matrix(snpRelMat)+diag(.0005,length(snpRelMat[,1]),length(snpRelMat[,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05f0523-50a6-4b78-a51e-e9d62caca221",
   "metadata": {},
   "source": [
    "Mapping the rows/columns in the relationship matrix `Gsnp` with the levels of variety in the datafile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f247e-74f8-4987-8abf-6f86827bedc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Map elements in the relationship matrix to the phenotypes\n",
    "rownames(Gsnp)=levels(dataf$variety)\n",
    "colnames(Gsnp)=levels(dataf$variety)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded8981-f515-46e2-a6e5-800805cb523e",
   "metadata": {},
   "source": [
    "Generating a heatmap of the genomic relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc4e54d-45ad-4d9c-a07e-c9970196e6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image(Gsnp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b942ca-f266-44ec-a1da-7959a41b6c78",
   "metadata": {},
   "source": [
    "Setting the inverse attribute to FALSE so sommer knows to take the inverse when setting up the mixed model equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8da34-1b18-4f98-ae58-1d5090376c29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attr(Gsnp, \"INVERSE\")=FALSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e88cbd-343b-4a42-aa7a-37f6bf2037c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we will fit 2 different GXE models in sommer, differing based on the specified covariance structure of the genetics effects across environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597d9976-a3e9-4cf8-938e-13fa163b8031",
   "metadata": {},
   "source": [
    "# Model 1 Genomic BLUP (No GxE effect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be818f7d-26b6-445a-9bcf-58d49e3de791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model 1\n",
    "mNoGE <- sommer::mmer(phenotype~loc, \n",
    "              random= ~ vsr(variety, Gu=Gsnp),\n",
    "              rcov= ~ units,\n",
    "              data=dataf, verbose = TRUE)\n",
    "#Looking at the summary of the results\n",
    "summary(mNoGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5aef7-08c8-4637-827b-c55beb731f98",
   "metadata": {},
   "source": [
    "Now we will generate the GBLUPs using the predict.mmer function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09890ae1-c193-4967-af9a-f75bd0965f9b",
   "metadata": {},
   "source": [
    "Setting up the Dtable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9998160f-c2e1-4f65-ae42-94080f9c4bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtNoGE=mNoGE$Dtable\n",
    "dtNoGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab22d03-4508-4e4f-bf66-0f4db2ea78ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtNoGE[1,\"include\"]=TRUE # intercept\n",
    "dtNoGE[2,\"include\"]=TRUE # loc\n",
    "dtNoGE[2,\"average\"]=TRUE # loc\n",
    "dtNoGE[3,\"include\"]=TRUE # variety\n",
    "dtNoGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a01ef99-a42a-4999-8b40-314c5ea2ef4e",
   "metadata": {},
   "source": [
    "Generating GBLUPs using predict.mmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639f448f-7888-40cf-b609-7f2c72fc24d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Using the predict function to get the estimates of each variety\n",
    "aNoGE=sommer::predict.mmer(mNoGE,Dtable=dtNoGE,D = \"variety\")\n",
    "pNoGE=aNoGE$pvals\n",
    "pNoGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35256983-8540-4d1e-b0d3-6b4813ac1fc4",
   "metadata": {},
   "source": [
    "To estimate accuracy and compare to other models we will be correlating estimates of this model with the true GxE effects. To do this we will assign the same estimate for variety for each of the 3 locations and create a vector that has each GBLUP repeated 3 times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634ce9c-71b6-4d94-ad23-1fd1f90dc39e",
   "metadata": {},
   "source": [
    "We will do this using for loops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a2a0c-034a-46e9-abf5-166a9352ae83",
   "metadata": {},
   "source": [
    "First we allocate a vector of length 360 to store 3 GBLUPs for each of the 120 varities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab77499-44c4-4157-9790-f0be017aae9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pNoGE360=rep(0,360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f7ad06-0b4c-4fc4-986d-c648bc705079",
   "metadata": {},
   "source": [
    "Now we use nested for loops to assign values to the vector `pNoGE360` in the disired order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363feb2-7a34-453d-8b6c-1845a52a3417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count=1 # counter to track the position in pNoGE360\n",
    "for(i in c(1:120)){ # for loop to cycle through the 120 GBLUP estimates in pNoGE\n",
    "  \n",
    "    for (j in c(1:3)){ # for loop to move 3 position in the vector pNoGE360 to duplicate GBLUPs\n",
    "      \n",
    "        pNoGE360[count]= pNoGE$predicted.value[i]\n",
    "       count=count+1 # adding 1 to the counter to move to the next position \n",
    "    } # closing for loop to move 3 position in the vector pNoGE360 to duplicate GBLUPs\n",
    "\n",
    "} # closing for loop to cycle through the 120 GBLUP estimates in pNoGE\n",
    "pNoGE360=as.double(pNoGE360)\n",
    "head(pNoGE360) # looking at the first positions in the vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ba052-03d8-49a4-b140-cb4c4c80f20d",
   "metadata": {},
   "source": [
    "# Model 2 Compound Symetric (no genomic relationship matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907dffe6-c804-49ad-b67c-435799223dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model 2\n",
    "mgeCS <- sommer::mmer(phenotype~loc,\n",
    "              random= ~ vsr(variety) + vsr(loc:variety),\n",
    "              rcov= ~ units,\n",
    "              data=dataf, verbose = TRUE)\n",
    "#Looking at the summary of the results\n",
    "summary(mgeCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a19e904-c690-4573-8671-dd97e0cd810f",
   "metadata": {},
   "source": [
    "Looking at `$varcomp` we can see there is significant GxE variance (.3668) indicating the presence of GxE. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba92293-3081-4b93-905e-5776ddd989b1",
   "metadata": {},
   "source": [
    "No let's use the predict function to get GBLUPs for each location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c45124-04f1-468d-a655-d4a6249ad0b0",
   "metadata": {},
   "source": [
    "First we modify the Dtable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5966a3-2281-446c-b8c6-a6507e8d3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtCS=mgeCS$Dtable\n",
    "dtCS\n",
    "dtCS[1,\"include\"]=TRUE # intercept\n",
    "dtCS[2,\"include\"]=TRUE # loc\n",
    "dtCS[2,\"average\"]=TRUE # loc\n",
    "dtCS[3,\"include\"]=TRUE # variety\n",
    "dtCS[4,\"include\"]=TRUE # loc:variety\n",
    "dtCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eccd055-460d-48c9-a365-32f0a42b8fa9",
   "metadata": {},
   "source": [
    "Now we generate the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c8970-51ca-420e-8239-5390f26b597a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aCS=sommer::predict.mmer(mgeCS, Dtable=dtCS, D=\"loc:variety\")\n",
    "pCS=aCS$pvals\n",
    "pCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0358421-ca4b-401d-b2c2-5f1a362f0b4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "For the purposes of calculating the accuracy of the two different models we will use the ture values from the input file \"TrueValues.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c121b7bd-1677-48a4-998a-439e7a845a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trueGE=read.csv(\"datasets/TrueValues.csv\",header=TRUE)\n",
    "head(trueGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeb7619-e64a-4f66-8eef-c5378ad23a00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Printing out the correlations\n",
    "print(\"correlation of preditions from model 1 (no GxE) with true values\")\n",
    "print(cor(pNoGE360,trueGE$TrueGE))\n",
    "print(\"correlation of GxE preditions\")\n",
    "print(cor(pCS$predicted.value,trueGE$TrueGE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0302fe53-32fc-499c-a1c4-0f4b2b2804af",
   "metadata": {},
   "source": [
    "# Random and Fixed Effects\n",
    "When to treat something as a random effect?\n",
    "\n",
    "The decisiosn to treat something as random or fixed in a model is not always clear, but will depend on several factors:\n",
    "\n",
    "**What is the purpose of the analysis, and what will the estimates be used for?**\n",
    "* When conducting hypothesis testing it is often best to treat the effects of interest as fixed to facilitate the use of standard statistical tests (i.e. t-test)\n",
    "* When using the estimates to for ranking (i.e. select the top 10% of all varieties to advance) treating the effect as random can improve accuracy as we have seen in the examples used in this course.\n",
    "\n",
    "**Do you think prior knowledge on the the statistical distribution will improve accuracy?**\n",
    "* We have seen in this course that the use of prior knowledge relating to genetic relatedness can improve accuracy.\n",
    "* The degree to which knowledge of the statistical distribution of a variable will impact the accuracy of estimates depends on the amount of data we have. When estimating the genetic performance of a variety with 100 plots of data, the impact of the prior knowledge of the distribution would be less than if we only had 2 plots of data.\n",
    "* Think of prior iformation on statistical distributions as a suppliment to observed phenotypic data. The less phenotypic data available, on a specific variety for instance, the more the prior knowledge of the statistical distributoin will impact the estimates.\n",
    "\n",
    "**Is there enough information to accurately estimate the paramerters of the the statistical distribution?**\n",
    "* For effects of interest it is important to have reliable estimates of variance and covariance components for the associated statistical distributions. \n",
    "* If I have an experiment with only two environments, I shouldn't expect to get a good variance component estimate for the distribution of environmental effects. In this case it is probably best treat this effect as fixed assuming you have no prior knowledge of the true value of the variance component and have enough data to estimate as a fixed effect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4ded49-d307-41c2-a496-e18cfe096ef3",
   "metadata": {},
   "source": [
    "# Final Activity\n",
    "Insert new code cells in the notebook and modify the code for the compound symetric model to include the genomic relationship matrix for the main effect.\n",
    "\n",
    "Use the predict function to get the GBLUPs and compare the results to model 1 (no GxE) and model 2 (compound symetric with no genomic relationship matrix). **Which model was most accurate? (use model output and correlations with true values to justify your answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dd34ee-582c-44e5-92d1-f4ce4e3dd2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2\n",
    "mgeCSwGRM <- sommer::mmer(phenotype~loc,\n",
    "              random= ~ ,\n",
    "              rcov= ~ units,\n",
    "              data=dataf, verbose = TRUE)\n",
    "#Look at the summary of the results\n",
    "\n",
    "\n",
    "#Generate predictions using the Dtable\n",
    "\n",
    "\n",
    "\n",
    "#Calculate correlations for all model\n",
    "print(\"correlation of predictions from model 1 (no GxE) with true values\")\n",
    "print()\n",
    "print(\"correlation of GxE predictions\")\n",
    "print()\n",
    "print(\"correlation of GxE predictions with GRM\")\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aebfd28-8954-45fa-b453-a53714c5f731",
   "metadata": {},
   "source": [
    "# Answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec814d-9032-4bbf-a292-2d9d08826c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
